{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "915f50e9",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a2319c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import re\n",
    "import html\n",
    "# import emoji\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73d6e6",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f399bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "MAX_LEN = 128  # good choice as max length was 67 in data overview\n",
    "DATA_DIR = \"../Data\"\n",
    "OUTPUT_FILE = os.path.abspath(os.path.join(DATA_DIR, \"mams_processed_bert\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108d36ec",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0942ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'mams_train_parsed.csv'))\n",
    "df_val = pd.read_csv(os.path.join(DATA_DIR, 'mams_val_parsed.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b772801",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4d023e",
   "metadata": {},
   "source": [
    "## remove nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7ac7cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df_val = df_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3dc3374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df train: (18275, 3)\n",
      "Shape of df val: (2220, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of df train: {df.shape}')\n",
    "print(f'Shape of df val: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180c2b1",
   "metadata": {},
   "source": [
    "## remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "81e87fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de072887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df train: (17045, 3)\n",
      "Shape of df val: (2220, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of df train: {df.shape}')\n",
    "print(f'Shape of df val: {df_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4b3b7",
   "metadata": {},
   "source": [
    "# Label Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2fac49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'positive': 2, 'neutral': 1, 'negative': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afacf071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_labels(df):\n",
    "    if df['label'].dtype == 'object':\n",
    "        df['label'] = df['label'].str.lower().map(label_map)\n",
    "    else: raise print('data type is not object')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1faca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = map_labels(df)\n",
    "df_val = map_labels(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "41f7653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>aspect</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It might be the best sit down food I've had in...</td>\n",
       "      <td>food</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might be the best sit down food I've had in...</td>\n",
       "      <td>place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hostess was extremely accommodating when we ar...</td>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hostess was extremely accommodating when we ar...</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We were a couple of minutes late for our reser...</td>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         aspect  label\n",
       "0  It might be the best sit down food I've had in...           food      2\n",
       "1  It might be the best sit down food I've had in...          place      1\n",
       "2  Hostess was extremely accommodating when we ar...          staff      2\n",
       "3  Hostess was extremely accommodating when we ar...  miscellaneous      1\n",
       "4  We were a couple of minutes late for our reser...  miscellaneous      1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe787c",
   "metadata": {},
   "source": [
    "# Convert to Hugging Face Dataset format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2de35749",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df),\n",
    "    \"validation\": Dataset.from_pandas(df_val)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e0bc7",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2fc340bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # decode html\n",
    "    text = html.unescape(str(text))\n",
    "    # remove urls and user handles\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"[URL]\", text)\n",
    "    text = re.sub(r'@\\w+', '[USER]', text)\n",
    "    # Demojize\n",
    "    #text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    # remove excessive whitespace\n",
    "    text = re.sub(r'\\s', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cf209e",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "485cc850",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9da5de1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    cleaned_batch_texts = [clean_text(t) for t in examples[\"text\"]]\n",
    "    \n",
    "    return tokenizer(\n",
    "        cleaned_batch_texts,    # Batch of 1000 cleaned sentences\n",
    "        examples[\"aspect\"],     # Batch of 1000 aspects\n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=MAX_LEN\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "658b1040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 17045/17045 [00:02<00:00, 8409.24 examples/s] \n",
      "Map: 100%|██████████| 2220/2220 [00:00<00:00, 6460.35 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de56f8d",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab348774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['text',\n",
       "  'aspect',\n",
       "  'label',\n",
       "  '__index_level_0__',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask'],\n",
       " 'validation': ['text',\n",
       "  'aspect',\n",
       "  'label',\n",
       "  'input_ids',\n",
       "  'token_type_ids',\n",
       "  'attention_mask']}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a9869945",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['input_ids', 'attention_mask', 'token_type_ids', 'label']\n",
    "tokenized_datasets.set_format(type='torch', columns=columns_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af91f1",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "43154847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed dataset to d:\\My Projects\\Aspect-Based Sentiment Anslaysis\\Data\\mams_processed_bert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 17045/17045 [00:00<00:00, 146261.54 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2220/2220 [00:00<00:00, 177207.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Ready for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving processed dataset to {OUTPUT_FILE}...\")\n",
    "tokenized_datasets.save_to_disk(OUTPUT_FILE)\n",
    "print(\"✅ Done! Ready for training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
