# ğŸ¤– Aspect-Based Sentiment Analysis (ABSA) API

<div align="center">

![Python](https://img.shields.io/badge/python-3.11+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)
![PyTorch](https://img.shields.io/badge/pytorch-2.0+-orange.svg)
[![Kaggle](https://img.shields.io/badge/kaggle-blue?logo=kaggle&logoColor=white)](https://www.kaggle.com/mohammed237)

A high-performance REST API for **Aspect-Based Sentiment Analysis** that processes both individual texts and large-scale CSV datasets using fine-tuned BERT models.

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Model Setup](#-model-setup) â€¢ [API Docs](#-api-documentation)

</div>

---

## ğŸš€ Features

- ğŸ§  **Fine-Tuned BERT** trained on MAMS dataset + SpaCy for aspect extraction
- âš¡ **Fast & Efficient** async processing for both text and CSV files
- ğŸ” **JWT Authentication** for secure API access
- ğŸ“Š **Unified Session System** handles both text and file uploads
- ğŸ“‘ **OpenAPI/Swagger UI** with interactive documentation
- âš¡ **Ultra-Fast Performance** with async/await support

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[Client] -->|Text/CSV| B[FastAPI]
    B --> C[BERT Model]
    C -->|Results| D[(Database)]
    D --> A
```

**Workflow**: Text/CSV requests â†’ instant analysis â†’ results stored in database

---

## ğŸ› ï¸ Tech Stack

| Layer    | Technology                       |
| -------- | -------------------------------- |
| **API**  | FastAPI + Pydantic               |
| **ML**   | PyTorch + Transformers + SpaCy   |
| **Auth** | JWT (python-jose)                |
| **DB**   | SQLite (dev) / PostgreSQL (prod) |
| **ORM**  | SQLAlchemy                       |

---

## âš¡ Quick Start

### Prerequisites

- Python 3.11+
- Git

### Installation

```bash
# 1. Clone and navigate
git clone https://github.com/yourusername/absa-api.git
cd absa-api

# 2. Setup virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt
python -m spacy download en_core_web_sm

# 4. Setup environment variables
cp .env.example .env
# Edit .env with your configuration

# 5. Setup database
alembic upgrade head
```

### Run the Application

```bash
# Start API Server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**âœ… API Ready**: http://127.0.0.1:8000  
**ğŸ“– Docs**: http://127.0.0.1:8000/docs  
**ğŸ“– ReDoc**: http://127.0.0.1:8000/redoc

---

## ğŸ§  Model Setup

The fine-tuned BERT model is required for sentiment analysis. Choose one option:

### Option 1: Download From Kaggle (Easiest way)

**[Download Model](https://www.kaggle.com/models/mohammed237/absa-bert-model)**

### Option 2: Train Locally (Recommended for customization)

- [**Download the dataset**](https://www.kaggle.com/datasets/mohammed237/mams-processed-bert)

- Run train Notebook

  ```bash
    jupyter notebook Notebooks/train.ipynb
  ```

- Fine-tune BERT for aspect-based sentiment analysis
- Save the model to `./models/bert_absa/`

### Option 3: Train on Kaggle (For more details and GPU access)

1. Open the Kaggle notebook **[ABSA BERT Training](https://www.kaggle.com/code/mohammed237/absa-train-bert)** and run it
2. Enable GPU accelerator in notebook settings
3. Run all cells to train the model
4. Download the trained model from Kaggle output
5. Place in `./models/bert_absa/` directory

**Model Directory Structure**:

```
models/
â””â”€â”€ bert_absa/
    â”œâ”€â”€ config.json
    â”œâ”€â”€ pytorch_model.bin
    â””â”€â”€ vocab.txt
```

---

## ğŸ“– API Documentation

**Interactive Docs**: http://127.0.0.1:8000/docs  
**ReDoc**: http://127.0.0.1:8000/redoc

### Quick Reference

| Endpoint                        | Method | Description                     | Auth |
| ------------------------------- | ------ | ------------------------------- | ---- |
| `/api/v1/register`              | POST   | Register a new user             | âŒ   |
| `/api/v1/login`                 | POST   | Authenticate user and get token | âŒ   |
| `/api/v1/analyze/`              | POST   | Analyze text                    | âœ…   |
| `/api/v1/upload/`               | POST   | upload csv file                 | âœ…   |
| `/api/v1/history/`              | GET    | Get user history                | âœ…   |
| `/api/v1/history/{session_id}/` | GET    | Get session details             | âœ…   |

### Using the API with Swagger UI

FastAPI comes with built-in interactive API documentation. Simply navigate to:

**Swagger UI**: http://127.0.0.1:8000/docs

#### How to use Swagger UI:

1. **Authentication**:

   - First, register a new user using the `/api/v1/register` endpoint
   - Login using `/api/v1/login` to get your access token
   - Click the **"Authorize"** button (ğŸ”’) at the top right
   - Enter your token in the format: `Bearer YOUR_TOKEN`
   - Click "Authorize" and then "Close"

2. **Text Analysis**:

   - Navigate to the `/api/v1/analyze/` POST endpoint
   - Click "Try it out"
   - Enter your text in the request body:
     ```json
     {
       "text": "The food was excellent but the service was slow."
     }
     ```
   - Click "Execute" to see results

3. **CSV Upload**:

   - Navigate to the `/api/v1/upload/` POST endpoint
   - Click "Try it out"
   - Click "Choose File" and select your CSV file
   - Click "Execute" to upload and process

4. **View History**:
   - Use `/api/v1/history/` to see all your analysis sessions
   - Use `/api/v1/history/{session_id}/` to get detailed results for a specific session

All responses, request schemas, and status codes are documented interactively in Swagger UI!

---

## ğŸ“ Project Structure

```
absa-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ deps.py          # API dependencies
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py            # Configuration settings
â”‚   â”‚   â””â”€â”€ security.py          # JWT & password hashing
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # Database base class
â”‚   â”‚   â”œâ”€â”€ crud_user.py         # User CRUD operations
â”‚   â”‚   â””â”€â”€ session.py           # Database session
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analysis.py          # Analysis model
â”‚   â”‚   â”œâ”€â”€ session.py           # Session model
â”‚   â”‚   â””â”€â”€ user.py              # User model
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ analysis.py          # Analysis schemas
â”‚   â”‚   â”œâ”€â”€ session.py           # Session schemas
â”‚   â”‚   â””â”€â”€ user.py              # User schemas
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ ai_model.py          # BERT model & inference
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ model/
â”‚   â””â”€â”€ bert_absa/               # Fine-tuned BERT model
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚       â””â”€â”€ vocab.txt
â”œâ”€â”€ main.py                      # FastAPI application entry
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```
